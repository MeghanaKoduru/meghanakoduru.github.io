glm.fit=glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
glm.probs=predict(glm.fit,newdata=Smarket[!train,],type="response")
glm.pred=ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
106/(76+106)
library(haven)
TEDS_2016 <- read_stata("https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true")
glm.vt <- glm(votetsai~female, data = TEDS_2016, family = binomial)
summary(glm.vt)
glm.vt2 <- glm(votetsai~female + KMT + DPP + age + edu + income, data = TEDS_2016, family = binomial)
summary(glm.vt2)
names(glm.vt2)
glm.vt3 <- glm(votetsai~female + KMT + DPP + age + edu + income + Independence + Econ_worse + Govt_dont_care + Minnan_father + Mainland_father + Taiwanese, data=TEDS_2016,family=binomial)
summary(glm.vt3)
library(easypackages)
libraries("arm","MASS","ISLR")
attach(Boston)
names(Boston)
?Boston
plot(medv~lstat,Boston, pch=20, cex=.8, col="steelblue")
fit1=lm(medv~lstat,data=Boston)
fit1
summary(fit1)
abline(fit1,col="firebrick")
names(fit1)
confint(fit1)
predict(fit1,data.frame(lstat=c(0,5,10,15)),interval="confidence")
predict(fit1,data.frame(lstat=c(0,5,10,15)),interval="prediction")
fit2=lm(medv~lstat+age,data=Boston)
summary(fit2)
fit3=lm(medv~.,Boston)
summary(fit3)
par(mfrow=c(2,2))
plot(fit3,pch=20, cex=.8, col="steelblue")
mtext("fit3", side = 3, line = - 2, cex = 2, outer = TRUE)
fit4=update(fit3,~.-age-indus)
summary(fit4)
par(mfrow=c(2,2), main="fit4")
plot(fit4,pch=20, cex=.8, col="steelblue")
mtext("fit4", side = 3, line = - 2, cex = 2, outer = TRUE)
par(mfrow=c(1,1))
arm::coefplot(fit4)
fit5=lm(medv~lstat*age,Boston) # include both variables and the interaction term x1:x2
summary(fit5)
fit6=lm(medv~lstat +I(lstat^2),Boston); summary(fit6)
par(mfrow=c(1,1))
plot(medv~lstat, pch=20, col="forestgreen")
points(lstat,fitted(fit6),col="firebrick",pch=20)
fit7=lm(medv~poly(lstat,4))
points(lstat,fitted(fit7),col="steelblue",pch=20)
names(Carseats)
summary(Carseats)
fit1=lm(Sales~.+Income:Advertising+Age:Price,Carseats)
summary(fit1)
attach(Carseats)
contrasts(Carseats$ShelveLoc)
?contrasts
# Install the easypackages package
install.packages(c("easypackages","XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats"))
library(easypackages)
libraries("XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats")
install.packages(c("easypackages", "XML", "wordcloud", "RColorBrewer", "NLP", "tm", "quanteda", "quanteda.textstats"))
# Install the easypackages package
## install.packages(c("easypackages","XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats"))
library(easypackages)
libraries("XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats")
# Download text data from website
churchill_speech <-URLencode("http://www.historyplace.com/speeches/churchill-hour.htm")
# use htmlTreeParse function to read and parse paragraphs
doc.html<- htmlTreeParse(churchill_speech, useInternal=TRUE)
churchill <- unlist(xpathApply(doc.html, '//p', xmlValue))
head(churchill, 3)
words.vec <- VectorSource(churchill)
# Check the class of words.vec
class(words.vec)
# Create Corpus object for preprocessing
words.corpus <- Corpus(words.vec)
inspect(words.corpus)
# Install the easypackages package
install.packages(c("easypackages","XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats"))
library(easypackages)
libraries("XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats")
install.packages(c("easypackages", "XML", "wordcloud", "RColorBrewer", "NLP", "tm", "quanteda", "quanteda.textstats"))
# Install the easypackages package
## install.packages(c("easypackages","XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats"))
library(easypackages)
libraries("XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats")
# Check the class of words.vec
class(words.vec)
# Create Corpus object for preprocessing
words.corpus <- Corpus(words.vec)
inspect(words.corpus)
## install.packages(c("easypackages","MASS","ISLR","arm"))
library(easypackages)
libraries("arm","MASS","ISLR")
## Load datasets from MASS and ISLR packages
attach(Boston)
### Simple linear regression
names(Boston)
# What is the Boston dataset?
?Boston
plot(medv~lstat,Boston, pch=20, cex=.8, col="steelblue")
fit1=lm(medv~lstat,data=Boston)
fit1
summary(fit1)
abline(fit1,col="firebrick")
names(fit1)
confint(fit1)
# Predictions using values in lstat
predict(fit1,data.frame(lstat=c(0,5,10,15)),interval="confidence") # confidence intervals
predict(fit1,data.frame(lstat=c(0,5,10,15)),interval="prediction") # prediction intervals
# Prediction interval uses sample mean and takes into account the variability of the estimators for μ and σ.
# Therefore, the interval will be wider.
### Multiple linear regression
fit2=lm(medv~lstat+age,data=Boston)
summary(fit2)
fit3=lm(medv~.,Boston)
summary(fit3)
par(mfrow=c(2,2))
plot(fit3,pch=20, cex=.8, col="steelblue")
mtext("fit3", side = 3, line = - 2, cex = 2, outer = TRUE)
# Update function to re-specify the model, i.e. include all but age and indus variables
fit4=update(fit3,~.-age-indus)
summary(fit4)
# Set the next plot configuration
par(mfrow=c(2,2), main="fit4")
plot(fit4,pch=20, cex=.8, col="steelblue")
mtext("fit4", side = 3, line = - 2, cex = 2, outer = TRUE)
# Uses coefplot to plot coefficients.  Note the line at 0.
par(mfrow=c(1,1))
arm::coefplot(fit4)
### Nonlinear terms and Interactions
fit5=lm(medv~lstat*age,Boston) # include both variables and the interaction term x1:x2
summary(fit5)
## I() identity function for squared term to interpret as-is
## Combine two command lines with semicolon
fit6=lm(medv~lstat +I(lstat^2),Boston); summary(fit6)
par(mfrow=c(1,1))
plot(medv~lstat, pch=20, col="forestgreen")
points(lstat,fitted(fit6),col="firebrick",pch=20)
fit7=lm(medv~poly(lstat,4))
points(lstat,fitted(fit7),col="steelblue",pch=20)
###Qualitative predictors
names(Carseats)
summary(Carseats)
fit1=lm(Sales~.+Income:Advertising+Age:Price,Carseats) # add two interaction terms
summary(fit1)
attach(Carseats)
contrasts(Carseats$ShelveLoc) # what is contrasts function?
?contrasts
### Writing an R function to combine the lm, plot and abline functions to
### create a one step regression fit plot function
regplot=function(x,y){
fit=lm(y~x)
plot(x,y, pch=20)
abline(fit,col="firebrick")
}
# Install the easypackages package
## install.packages(c("easypackages","XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats"))
library(easypackages)
libraries("XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats")
# Download text data from website
churchill_speech <-URLencode("http://www.historyplace.com/speeches/churchill-hour.htm")
# Install the easypackages package
## install.packages(c("easypackages","XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats"))
library(easypackages)
libraries("XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats")
# Download text data from website
churchill_speech <-URLencode("http://www.historyplace.com/speeches/churchill-hour.htm")
# use htmlTreeParse function to read and parse paragraphs
doc.html<- htmlTreeParse(churchill_speech, useInternal=TRUE)
churchill <- unlist(xpathApply(doc.html, '//p', xmlValue))
head(churchill, 3)
words.vec <- VectorSource(churchill)
# Check the class of words.vec
class(words.vec)
# Create Corpus object for preprocessing
words.corpus <- Corpus(words.vec)
inspect(words.corpus)
# Turn all words to lower case
words.corpus <- tm_map(words.corpus, content_transformer(tolower))
# Remove punctuations, numbers
words.corpus <- tm_map(words.corpus, removePunctuation)
words.corpus <- tm_map(words.corpus, removeNumbers)
# How about stopwords, then uniform bag of words created
words.corpus <- tm_map(words.corpus, removeWords, stopwords("english"))
# Create Term Document Matric
tdm <- TermDocumentMatrix(words.corpus)
inspect(tdm)
m <- as.matrix(tdm)
wordCounts <- rowSums(m)
wordCounts <- sort(wordCounts, decreasing=TRUE)
head(wordCounts)
# Create Wordcloud
cloudFrame<-data.frame(word=names(wordCounts),freq=wordCounts)
set.seed(1234)
wordcloud(cloudFrame$word,cloudFrame$freq)
wordcloud(names(wordCounts),wordCounts, min.freq=1,random.order=FALSE, max.words=200,scale=c(4,.5), rot.per=0.35,colors=brewer.pal(8,"Dark2"))
# Install the easypackages package
## install.packages(c("easypackages","XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats"))
library(easypackages)
libraries("XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats")
# Download text data from website
churchill_speech <-URLencode("http://www.historyplace.com/speeches/churchill-hour.htm")
# use htmlTreeParse function to read and parse paragraphs
doc.html<- htmlTreeParse(churchill_speech, useInternal=TRUE)
churchill <- unlist(xpathApply(doc.html, '//p', xmlValue))
head(churchill, 3)
words.vec <- VectorSource(churchill)
# Check the class of words.vec
class(words.vec)
# Create Corpus object for preprocessing
words.corpus <- Corpus(words.vec)
inspect(words.corpus)
# Turn all words to lower case
words.corpus <- tm_map(words.corpus, content_transformer(tolower))
# Remove punctuations, numbers
words.corpus <- tm_map(words.corpus, removePunctuation)
words.corpus <- tm_map(words.corpus, removeNumbers)
# How about stopwords, then uniform bag of words created
words.corpus <- tm_map(words.corpus, removeWords, stopwords("english"))
# Create Term Document Matric
tdm <- TermDocumentMatrix(words.corpus)
inspect(tdm)
m <- as.matrix(tdm)
wordCounts <- rowSums(m)
wordCounts <- sort(wordCounts, decreasing=TRUE)
head(wordCounts)
# Create Wordcloud
cloudFrame<-data.frame(word=names(wordCounts),freq=wordCounts)
set.seed(1234)
wordcloud(cloudFrame$word,cloudFrame$freq)
wordcloud(names(wordCounts),wordCounts, min.freq=1,random.order=FALSE, max.words=200,scale=c(4,.5), rot.per=0.35,colors=brewer.pal(8,"Dark2"))
#  N-gram with two to three words
textstat_collocations(churchill, size = 2:3)
# Install the easypackages package
## install.packages(c("easypackages","XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats"))
library(easypackages)
libraries("XML","wordcloud","RColorBrewer","NLP","tm","quanteda","quanteda.textstats")
# Download text data from website
churchill_speech <-URLencode("http://www.historyplace.com/speeches/churchill-hour.htm")
# use htmlTreeParse function to read and parse paragraphs
doc.html<- htmlTreeParse(churchill_speech, useInternal=TRUE)
churchill <- unlist(xpathApply(doc.html, '//p', xmlValue))
head(churchill, 3)
words.vec <- VectorSource(churchill)
# Check the class of words.vec
class(words.vec)
# Create Corpus object for preprocessing
words.corpus <- Corpus(words.vec)
inspect(words.corpus)
# Turn all words to lower case
words.corpus <- tm_map(words.corpus, content_transformer(tolower))
# Remove punctuations, numbers
words.corpus <- tm_map(words.corpus, removePunctuation)
words.corpus <- tm_map(words.corpus, removeNumbers)
# How about stopwords, then uniform bag of words created
words.corpus <- tm_map(words.corpus, removeWords, stopwords("english"))
# Create Term Document Matric
tdm <- TermDocumentMatrix(words.corpus)
inspect(tdm)
m <- as.matrix(tdm)
wordCounts <- rowSums(m)
wordCounts <- sort(wordCounts, decreasing=TRUE)
head(wordCounts)
# Create Wordcloud
cloudFrame<-data.frame(word=names(wordCounts),freq=wordCounts)
set.seed(1234)
wordcloud(cloudFrame$word,cloudFrame$freq)
wordcloud(names(wordCounts),wordCounts, min.freq=1,random.order=FALSE, max.words=200,scale=c(4,.5), rot.per=0.35,colors=brewer.pal(8,"Dark2"))
#  N-gram with two to three words
textstat_collocations(churchill, size = 2:3)
## install.packages(c("easypackages","MASS","ISLR","arm"))
library(easypackages)
libraries("arm","MASS","ISLR")
## Load datasets from MASS and ISLR packages
attach(Boston)
### Simple linear regression
names(Boston)
# What is the Boston dataset?
?Boston
plot(medv~lstat,Boston, pch=20, cex=.8, col="steelblue")
fit1=lm(medv~lstat,data=Boston)
fit1
summary(fit1)
abline(fit1,col="firebrick")
names(fit1)
confint(fit1)
## install.packages(c("easypackages","MASS","ISLR","arm"))
library(easypackages)
libraries("arm","MASS","ISLR")
## Load datasets from MASS and ISLR packages
attach(Boston)
### Simple linear regression
names(Boston)
# What is the Boston dataset?
?Boston
plot(medv~lstat,Boston, pch=20, cex=.8, col="steelblue")
fit1=lm(medv~lstat,data=Boston)
fit1
summary(fit1)
abline(fit1,col="firebrick")
names(fit1)
confint(fit1)
# Predictions using values in lstat
predict(fit1,data.frame(lstat=c(0,5,10,15)),interval="confidence") # confidence intervals
predict(fit1,data.frame(lstat=c(0,5,10,15)),interval="prediction") # prediction intervals
# Prediction interval uses sample mean and takes into account the variability of the estimators for μ and σ.
# Therefore, the interval will be wider.
### Multiple linear regression
fit2=lm(medv~lstat+age,data=Boston)
summary(fit2)
fit3=lm(medv~.,Boston)
summary(fit3)
par(mfrow=c(2,2))
plot(fit3,pch=20, cex=.8, col="steelblue")
mtext("fit3", side = 3, line = - 2, cex = 2, outer = TRUE)
# Update function to re-specify the model, i.e. include all but age and indus variables
fit4=update(fit3,~.-age-indus)
summary(fit4)
# Set the next plot configuration
par(mfrow=c(2,2), main="fit4")
plot(fit4,pch=20, cex=.8, col="steelblue")
mtext("fit4", side = 3, line = - 2, cex = 2, outer = TRUE)
# Uses coefplot to plot coefficients.  Note the line at 0.
par(mfrow=c(1,1))
arm::coefplot(fit4)
### Nonlinear terms and Interactions
fit5=lm(medv~lstat*age,Boston) # include both variables and the interaction term x1:x2
summary(fit5)
## I() identity function for squared term to interpret as-is
## Combine two command lines with semicolon
fit6=lm(medv~lstat +I(lstat^2),Boston); summary(fit6)
par(mfrow=c(1,1))
plot(medv~lstat, pch=20, col="forestgreen")
points(lstat,fitted(fit6),col="firebrick",pch=20)
fit7=lm(medv~poly(lstat,4))
points(lstat,fitted(fit7),col="steelblue",pch=20)
###Qualitative predictors
names(Carseats)
summary(Carseats)
fit1=lm(Sales~.+Income:Advertising+Age:Price,Carseats) # add two interaction terms
summary(fit1)
attach(Carseats)
contrasts(Carseats$ShelveLoc) # what is contrasts function?
?contrasts
### Writing an R function to combine the lm, plot and abline functions to
### create a one step regression fit plot function
regplot=function(x,y){
fit=lm(y~x)
plot(x,y, pch=20)
abline(fit,col="firebrick")
}
attach(Carseats)
regplot(Price,Sales)
## Allow extra room for additional arguments/specifications
regplot=function(x,y,...){
fit=lm(y~x)
plot(x,y,...)
abline(fit,col="firebrick")
}
regplot(Price,Sales,xlab="Price",ylab="Sales",col="steelblue",pch=20)
# Load ISLR library
require(ISLR)
# Check dataset Smarket
?Smarket
names(Smarket)
summary(Smarket)
# Create a dataframe for data browsing
sm=Smarket
# Create a dataframe for data browsing
sm=Smarket
# Load ISLR library
require(ISLR)
# Check dataset Smarket
?Smarket
names(Smarket)
summary(Smarket)
# Create a dataframe for data browsing
sm=Smarket
# Bivariate Plot of inter-lag correlations
pairs(Smarket,col=Smarket$Direction,cex=.5, pch=20)
# Logistic regression
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5,"Up","Down")
attach(Smarket)
table(glm.pred,Direction)
mean(glm.pred==Direction)
# Make training and test set for prediction
train = Year<2005
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial, subset=train)
glm.probs=predict(glm.fit,newdata=Smarket[!train,],type="response")
glm.pred=ifelse(glm.probs >0.5,"Up","Down")
Direction.2005=Smarket$Direction[!train]
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
#Fit smaller model
glm.fit=glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
glm.probs=predict(glm.fit,newdata=Smarket[!train,],type="response")
glm.pred=ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
# Check accuracy rate
106/(76+106)
# Load ISLR library
require(ISLR)
# Check dataset Smarket
?Smarket
names(Smarket)
summary(Smarket)
# Check dataset Smarket
?Smarket
names(Smarket)
summary(Smarket)
# Create a dataframe for data browsing
sm=Smarket
# Bivariate Plot of inter-lag correlations
pairs(Smarket,col=Smarket$Direction,cex=.5, pch=20)
# Load ISLR library
require(ISLR)
# Check dataset Smarket
?Smarket
names(Smarket)
summary(Smarket)
# Create a dataframe for data browsing
sm=Smarket
# Bivariate Plot of inter-lag correlations
pairs(Smarket,col=Smarket$Direction,cex=.5, pch=20)
# Logistic regression
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,
data=Smarket,family=binomial)
summary(glm.fit)
glm.probs=predict(glm.fit,type="response")
glm.probs[1:5]
glm.pred=ifelse(glm.probs>0.5,"Up","Down")
attach(Smarket)
table(glm.pred,Direction)
mean(glm.pred==Direction)
#Fit smaller model
glm.fit=glm(Direction~Lag1+Lag2,
data=Smarket,family=binomial, subset=train)
glm.probs=predict(glm.fit,newdata=Smarket[!train,],type="response")
glm.pred=ifelse(glm.probs >0.5,"Up","Down")
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
# Check accuracy rate
106/(76+106)
library(haven)
TEDS_2016 <- read_stata("https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true")
glm.vt <- glm(votetsai~female, data = TEDS_2016, family = binomial)
summary(glm.vt)
glm.vt2 <- glm(votetsai~female + KMT + DPP + age + edu + income, data = TEDS_2016, family = binomial)
require(ISLR)
require(MASS)
require(descr)
attach(Smarket)
freq(Direction)
train = Year<2005
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)
Smarket.2005=subset(Smarket,Year==2005) # Creating subset with 2005 data for prediction
lda.pred=predict(lda.fit,Smarket.2005)
names(lda.pred)
lda.class=lda.pred$class
Direction.2005=Smarket$Direction[!train]
table(lda.class,Direction.2005)
data.frame(lda.pred)[1:5,]
table(lda.pred$class,Smarket.2005$Direction)
mean(lda.pred$class==Smarket.2005$Direction)
set.seed(1)
X = rnorm(100)
eps = rnorm(100)
Y <- 4 + 9*X - 2*X^2 + X^3 + eps
plot(X,Y, pch=20)
install.packages("leaps")
require(leaps)
regfit.full <- regsubsets(Y~poly(X,10,raw=T), data=data.frame(Y,X), nvmax=10)
(reg.summary <- summary(regfit.full))
plot(lda.fit, col="dodgerblue")
# Setup
require(ISLR)
require(MASS)
require(descr)
attach(Smarket)
## Linear Discriminant Analysis
freq(Direction)
train = Year<2005
lda.fit=lda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)
lda.fit
plot(lda.fit, col="dodgerblue")
Smarket.2005=subset(Smarket,Year==2005) # Creating subset with 2005 data for prediction
lda.pred=predict(lda.fit,Smarket.2005)
names(lda.pred)
lda.class=lda.pred$class
# Check dataset Smarket
?Smarket
names(Smarket)
summary(Smarket)
# Check dataset Smarket
?Smarket
names(Smarket)
# Check dataset Smarket
?Smarket
names(Smarket)
summary(Smarket)
